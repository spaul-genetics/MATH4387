<!DOCTYPE html>
<html>
<head>
  <title>Prediction</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Prediction',
                        subtitle: 'Chapter 4 and 5 of LMWR2',
                useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                      },

      // Author information
      presenters: [
            {
        name:  'Subrata Paul' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <script src="site_libs/header-attrs-2.4/header-attrs.js"></script>
  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            pre > code.sourceCode { white-space: pre; position: relative; }
            pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
            pre > code.sourceCode > span:empty { height: 1.2em; }
            code.sourceCode > span { color: inherit; text-decoration: inherit; }
            div.sourceCode { margin: 1em 0; }
            pre.sourceCode { margin: 0; }
            @media screen {
            div.sourceCode { overflow: auto; }
            }
            @media print {
            pre > code.sourceCode { white-space: pre-wrap; }
            pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
            }
            pre.numberSource code
              { counter-reset: source-line 0; }
            pre.numberSource code > span
              { position: relative; left: -4em; counter-increment: source-line; }
            pre.numberSource code > span > a:first-child::before
              { content: counter(source-line);
                position: relative; left: -1em; text-align: right; vertical-align: baseline;
                border: none; display: inline-block;
                -webkit-touch-callout: none; -webkit-user-select: none;
                -khtml-user-select: none; -moz-user-select: none;
                -ms-user-select: none; user-select: none;
                padding: 0 4px; width: 4em;
                color: #aaaaaa;
              }
            pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
            div.sourceCode
              {   }
            @media screen {
            pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
            }
            code span.al { color: #ff0000; font-weight: bold; } /* Alert */
            code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
            code span.at { color: #7d9029; } /* Attribute */
            code span.bn { color: #40a070; } /* BaseN */
            code span.bu { } /* BuiltIn */
            code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
            code span.ch { color: #4070a0; } /* Char */
            code span.cn { color: #880000; } /* Constant */
            code span.co { color: #60a0b0; font-style: italic; } /* Comment */
            code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
            code span.do { color: #ba2121; font-style: italic; } /* Documentation */
            code span.dt { color: #902000; } /* DataType */
            code span.dv { color: #40a070; } /* DecVal */
            code span.er { color: #ff0000; font-weight: bold; } /* Error */
            code span.ex { } /* Extension */
            code span.fl { color: #40a070; } /* Float */
            code span.fu { color: #06287e; } /* Function */
            code span.im { } /* Import */
            code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
            code span.kw { color: #007020; font-weight: bold; } /* Keyword */
            code span.op { color: #666666; } /* Operator */
            code span.ot { color: #007020; } /* Other */
            code span.pp { color: #bc7a00; } /* Preprocessor */
            code span.sc { color: #4070a0; } /* SpecialChar */
            code span.ss { color: #bb6688; } /* SpecialString */
            code span.st { color: #4070a0; } /* String */
            code span.va { color: #19177c; } /* Variable */
            code span.vs { color: #4070a0; } /* VerbatimString */
            code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
        
  </style>


</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">6/4/2020</p>
          </hgroup>
  </slide>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script>

<script>
    $(document).ready(function() {
    $('slide:not(.title-slide, .backdrop, .segue)').append('<footer></footer>');    
    $('footer').attr('url', "https://math5387.web.app");

  })
</script>

<style>
pre {
    display: block;
    font-family: monospace;
    white-space: pre;
    margin: 1em 0px;
    margin-top: 0em;
    margin-right: 0px;
    margin-bottom: -0.2em;
    margin-left: 0px;
}
footer:after {
    font-size: 12pt;
    content: attr(url);
    position: absolute;
    bottom: 5px;
    right: 60px;
    line-height: 1.9;
    display: block;
  }
slides > slide {
  font-family: 'Open Sans', Arial, sans-serif;
  font-size: 26px;
  color: black;
  width: 900px;
  height: 700px;
  margin-left: -450px;
  margin-top: -350px;
  padding: 0px 60px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  -ms-border-radius: 5px;
  -o-border-radius: 5px;
  border-radius: 5px;
  -webkit-transition: all 0.6s ease-in-out;
  -moz-transition: all 0.6s ease-in-out;
  -o-transition: all 0.6s ease-in-out;
  transition: all 0.6s ease-in-out;
}
slides > slide > hgroup + article {
  margin-top: 5px;
}
</style>

<slide class=""><hgroup><h2>The Natural Predictor</h2></hgroup><article  id="the-natural-predictor">

<p>Given a new set of regressor values, \(x_0=(1,x_{01},…,x_{0,p-1} )^T\), a natural predictor for the associated response is \(\hat{y}_0 = x_0^T\hat{\beta}\).</p>

<p>What is the uncertainty in our prediction?</p>

<ul>
<li>It depends on the type of prediction made.</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Confidence Intervals for Predictions</h2></hgroup><article  id="confidence-intervals-for-predictions">

<p>There are two types of predictions that are made from regression models.</p>

<ol>
<li>Prediction of the mean response.</li>
<li>Prediction of a future (or new) observation</li>
</ol>

<p>Consider building a regression model predicting the selling price of homes in a certain area based on predictors such as the number of bedrooms and closeness to a major highway.</p>

</article></slide><slide class=""><hgroup><h2>What we can predict?</h2></hgroup><article  id="what-we-can-predict">

<p>Consider building a regression model predicting the selling price of homes in a certain area based on predictors such as the number of bedrooms and closeness to a major highway.</p>

<p>Given a set of regressor values x_0, we might want to:</p>

<ul>
<li>Estimate the average selling price of a house with characteristics \(x_0\).

<ul>
<li>The average selling price is \(x_0^T \beta\), and we would estimate the average price by \(\hat{y}_0=x_0^T \hat{\beta}\).<br/></li>
<li>The parametric uncertainty of our estimate is only affected by our uncertainty in estimating \(\beta\).</li>
<li>Called <strong>prediction or estimation of the mean response</strong></li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>What we can predict?</h2></hgroup><article  id="what-we-can-predict-1">

<ul>
<li><p>Predict the future selling price of a specific house with characteristics \(x_0\).</p>

<ul>
<li>The selling price of this house is \(y_0=x_0^T \beta+\epsilon_0\).<br/></li>
<li>Since \(E(\epsilon_0 |X=x_0 )=0\), the predicted price for a new observation is also \(\hat{y}_0+\hat{\epsilon}_0=x_0^T \hat{\beta}+0=x_0^T \hat{\beta}\)<br/></li>
<li>The parametric uncertainty of our prediction is affected by our uncertainty in estimating \(\beta\) and the uncertainty associated with the error \(\epsilon_0\).</li>
<li>Called <strong>Prediction of a new or future response</strong></li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>Variance of the Estimation Error for the Mean</h2></hgroup><article  id="variance-of-the-estimation-error-for-the-mean">

<p>\[\begin{aligned}
var(x_0^T\hat{\beta}) = &amp; var(x_0^T(X^TX)^{-1}X^Ty) \\ = &amp; x_0^T(X^TX)^{-1}X^T var(y) \left(x_0^T(X^TX)^{-1}X^T\right)^T\\
=&amp; x_0^T(X^TX)^{-1}X^T var(y) X(X^TX)^{-1}x_0\\
=&amp; x_0^T(X^TX)^{-1}X^T \sigma^2 I X(X^TX)^{-1}x_0\\
=&amp; x_0^T(X^TX)^{-1}X^T  X(X^TX)^{-1}x_0 \sigma^2\\
=&amp; x_0^T(X^TX)^{-1}x_0 \sigma^2\\
\end{aligned}\]</p>

</article></slide><slide class=""><hgroup><h2>Variance of the Prediction Error for a new response</h2></hgroup><article  id="variance-of-the-prediction-error-for-a-new-response">

<p>\[\begin{aligned}
var(x_0^T\hat{\beta} +\epsilon) = &amp; var(x_0^T(X^TX)^{-1}X^Ty) +\sigma^2 &amp; \text{Assume Independence}\\ 
=&amp; \left(1+x_0^T(X^TX)^{-1}x_0\right) \sigma^2 \\
\end{aligned}\]</p>

</article></slide><slide class=""><hgroup><h2>CI for Mean Response</h2></hgroup><article  id="ci-for-mean-response">

<p>Since, \(\hat{y}_0 = x_0^T\hat{\beta} \sim N(x_0^T\beta, x_0^T(X^TX)^{-1}x_0 \sigma^2\),</p>

<p>\[\frac{\hat{y}_0 - x_0^T\beta}{\hat{\sigma}\sqrt{x_0^T(X^TX)^{-1}x_0}}\sim T_{n-p}.\]</p>

<p>A 100(1-)% CI for the mean response given \(x_0\), \[x_0^T\hat{\beta} \pm t_{n-p}^{\alpha/2} \hat{\sigma}\sqrt{x_0^T(X^TX)^{-1}x_0}.\]</p>

</article></slide><slide class=""><hgroup><h2>CI for New Response</h2></hgroup><article  id="ci-for-new-response">

<p>A 100(1-)% CI for a future response given \(x_0\), \[x_0^T\hat{\beta} \pm t_{n-p}^{\alpha/2} \hat{\sigma}\sqrt{1+x_0^T(X^TX)^{-1}x_0}.\]</p>

</article></slide><slide class=""><hgroup><h2>Prediction Interval</h2></hgroup><article  id="prediction-interval">

<p>A future observation is a random variable. Thus, the second type of interval is typically called a <strong>prediction interval (PI)</strong>.</p>

<ul>
<li>There is a 95% chance that the actual future value will fall within our prediction interval (in the context of constructing many intervals from independent samples of the population and our assumptions are correct).</li>
</ul>

<p>A confidence interval for the mean response is typically much narrower than the prediction interval for a new response (assuming the same x_0).</p>

</article></slide><slide class=""><hgroup><h2>Prediction VS Confidence</h2></hgroup><article  id="prediction-vs-confidence">

<pre class = 'prettyprint lang-r'>arrows(x0 = 5.7, y0 = ci(y)[1], x1 = 5.7, y1 = ci(y)[2], lwd = 3, code = 3, col = &#39;red&#39;)</pre>

<p><img src="prediction_files/figure-html/unnamed-chunk-1-1.png" width="720" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Simulated Example</h2></hgroup><article  id="simulated-example">

<pre class = 'prettyprint lang-r'>set.seed(123)
x = seq(1,20)
y = 2*x + rnorm(length(x), mean = 0, sd = 2)
lmod = lm(y~x)
plot(x,y)
abline(lmod, col = &#39;blue&#39;)</pre>

<p><img src="prediction_files/figure-html/unnamed-chunk-2-1.png" width="720" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Simulated Example</h2></hgroup><article  id="simulated-example-1">

<pre class = 'prettyprint lang-r'>set.seed(123)
new_obs = 2*11.5 + rnorm(100, mean = 0, sd = 2)
plot(x,y)
abline(lmod, col = &#39;blue&#39;)
points(rep(11.5, length(new_obs)), new_obs, col=&#39;red&#39;)</pre>

<p><img src="prediction_files/figure-html/unnamed-chunk-3-1.png" width="720" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Simulated Example</h2></hgroup><article  id="simulated-example-2">

<pre class = 'prettyprint lang-r'>set.seed(123)
mean_obs &lt;- c()
for(i in 1:100){
  obs = 2*12.5 + rnorm(10, mean = 0, sd = 2)
  mean_obs[i]&lt;-mean(obs)
}
plot(x,y)
abline(lmod, col = &#39;blue&#39;)
points(rep(11.5, length(new_obs)), new_obs, col=&#39;red&#39;)
points(rep(12.5, length(mean_obs)), mean_obs, col = &#39;green&#39;)</pre>

<p><img src="prediction_files/figure-html/unnamed-chunk-4-1.png" width="720" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Example - Body Fat</h2></hgroup><article  id="example---body-fat">

<p>Measuring body fat is not simple. Muscle and bone are denser than fat so an estimate of body density can be used to estimate the proportion of fat in the body. Measuring someone’s weight is easy but volume is more difficult. One method requires submerging the body underwater in a tank and measuring the increase in the water level. Most people would prefer not to be submerged underwater to get a measure of body fat, so we would like an easier method. In order to develop such a method, researchers recorded age, weight, height, and 10 body circumference measurements for 252 men. Each man’s percentage of body fat was accurately estimated by an underwater weighing technique. Can we predict body fat using only the easy-to-record measurements?</p>

</article></slide><slide class=""><hgroup><h2>Response for the median values of the predictors</h2></hgroup><article  id="response-for-the-median-values-of-the-predictors" class="smaller">

<pre class = 'prettyprint lang-r'>data(fat, package = &#39;faraway&#39;)
lmod &lt;- lm(brozek ~ age + weight + height + neck + chest + 
             abdom + hip + thigh + knee + ankle + biceps + 
             forearm + wrist, data=fat)
summary(lmod)</pre>

<pre >## 
## Call:
## lm(formula = brozek ~ age + weight + height + neck + chest + 
##     abdom + hip + thigh + knee + ankle + biceps + forearm + wrist, 
##     data = fat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.264  -2.572  -0.097   2.898   9.327 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -15.29255   16.06992  -0.952  0.34225    
## age           0.05679    0.02996   1.895  0.05929 .  
## weight       -0.08031    0.04958  -1.620  0.10660    
## height       -0.06460    0.08893  -0.726  0.46830    
## neck         -0.43754    0.21533  -2.032  0.04327 *  
## chest        -0.02360    0.09184  -0.257  0.79740    
## abdom         0.88543    0.08008  11.057  &lt; 2e-16 ***
## hip          -0.19842    0.13516  -1.468  0.14341    
## thigh         0.23190    0.13372   1.734  0.08418 .  
## knee         -0.01168    0.22414  -0.052  0.95850    
## ankle         0.16354    0.20514   0.797  0.42614    
## biceps        0.15280    0.15851   0.964  0.33605    
## forearm       0.43049    0.18445   2.334  0.02044 *  
## wrist        -1.47654    0.49552  -2.980  0.00318 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.988 on 238 degrees of freedom
## Multiple R-squared:  0.749,  Adjusted R-squared:  0.7353 
## F-statistic: 54.63 on 13 and 238 DF,  p-value: &lt; 2.2e-16</pre>

</article></slide><slide class=""><hgroup><h2>Response for the median values of the predictors</h2></hgroup><article  id="response-for-the-median-values-of-the-predictors-1">

<pre class = 'prettyprint lang-r'>x &lt;- model.matrix(lmod)
(x0&lt;-apply(x, 2, median))</pre>

<pre >## (Intercept)         age      weight      height        neck       chest 
##        1.00       43.00      176.50       70.00       38.00       99.65 
##       abdom         hip       thigh        knee       ankle      biceps 
##       90.95       99.30       59.00       38.50       22.80       32.05 
##     forearm       wrist 
##       28.70       18.30</pre>

<pre class = 'prettyprint lang-r'>(y0&lt;-sum(x0*coef(lmod)))</pre>

<pre >## [1] 17.49322</pre>

</article></slide><slide class=""><hgroup><h2>Response for the median values of the predictors</h2></hgroup><article  id="response-for-the-median-values-of-the-predictors-2">

<pre class = 'prettyprint lang-r'>predict(lmod, newdata = data.frame(t(x0)))</pre>

<pre >##        1 
## 17.49322</pre>

<p>Note: The data.frame object placed in the <code>new</code> argument must include columns with names matching the names of the predictor variables in the fitted model.</p>

</article></slide><slide class=""><hgroup><h2>Construct PI and CI</h2></hgroup><article  id="construct-pi-and-ci">

<pre class = 'prettyprint lang-r'>predict(lmod, newdata = data.frame(t(x0)), interval = &quot;prediction&quot;, level = 0.95)</pre>

<pre >##        fit     lwr      upr
## 1 17.49322 9.61783 25.36861</pre>

<pre class = 'prettyprint lang-r'>predict(lmod, newdata = data.frame(t(x0)), interval = &quot;confidence&quot;, level = 0.95)</pre>

<pre >##        fit      lwr      upr
## 1 17.49322 16.94426 18.04219</pre>

<p>The prediction interval ranges from 9.6% body fat up to 25.4%. This is pretty wide, so there may not be enough information for practical use.</p>

<p>The confidence interval for the mean response is 16.9% to 18.1%, which is much narrower.</p>

</article></slide><slide class=""><hgroup><h2>Interpretation of CI</h2></hgroup><article  id="interpretation-of-ci">

<p>The percentage of body fat between 16.94 and 18.04 are good estimates of the unknown mean percent body fat of the people with age –, height –, etc. In general, if we would repeat our sampling procedure infinitely, 95% of such constracted confidence intervals would contain the true mean percentage of body fat.</p>

</article></slide><slide class=""><hgroup><h2>Interpretation of PI</h2></hgroup><article  id="interpretation-of-pi">

<p>Given a person’s measurements are (age = 43, height = 70, etc.), the percengate of body fat will be between 9.62 to 25.37 with a confidence of 95%. In general, if we could repeat our sampling process infinitely, 95% of such constructed prediction intervals would contain the person’s true percent body fat.</p>

</article></slide><slide class=""><hgroup><h2>Extrapolation</h2></hgroup><article  id="extrapolation">

<p>Extrapolation is making statistical inference outside the range of the observed data.</p>

<ul>
<li>Quantitative extrapolation concerns x_0 that are far from the original data.</li>
<li>Prediction intervals become wider as we move away from the observed data.</li>
</ul>

<p>What happens when we predict body fat at the 95th percentile of the observed data?</p>

</article></slide><slide class=""><hgroup><h2>Measurements are at 95th percentile</h2></hgroup><article  id="measurements-are-at-95th-percentile">

<pre class = 'prettyprint lang-r'>(x1 &lt;- apply(x,2,function(x) quantile(x,0.95)))</pre>

<pre >## (Intercept)         age      weight      height        neck       chest 
##       1.000      67.000     225.650      74.500      41.845     116.340 
##       abdom         hip       thigh        knee       ankle      biceps 
##     110.760     112.125      68.545      42.645      25.445      37.200 
##     forearm       wrist 
##      31.745      19.800</pre>

<pre class = 'prettyprint lang-r'>predict(lmod, new = data.frame(t(x1)), interval=&quot;prediction&quot;)</pre>

<pre >##        fit      lwr      upr
## 1 30.01804 21.92407 38.11202</pre>

<pre class = 'prettyprint lang-r'>predict(lmod, new = data.frame(t(x1)), interval=&quot;confidence&quot;)</pre>

<pre >##        fit      lwr      upr
## 1 30.01804 28.07072 31.96537</pre>

<p>Our confidence interval for the mean is almost 4% wide instead of 1%! That is a large increase in our uncertainty!</p>

</article></slide><slide class=""><hgroup><h2>Graphical (Simulated Data)</h2></hgroup><article  id="graphical-simulated-data">

<p><img src="prediction_files/figure-html/unnamed-chunk-10-1.png" width="720" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Graphical (Simulated Data)</h2></hgroup><article  id="graphical-simulated-data-1">

<p><img src="prediction_files/figure-html/unnamed-chunk-11-1.png" width="720" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>Other Uncertainty</h2></hgroup><article  id="other-uncertainty">

<p>An additional source of variation is not accounted for in the previous intervals:</p>

<ul>
<li>What is the correct model for this data?</li>
</ul>

<p>We do our best to find a good model given the available data, but there will always be substantial <strong>model uncertainty</strong>, i.e., the form the model should take.</p>

<p><strong>Parametric uncertainty</strong> is accounted for using the methods we have learned.</p>

<p><strong>Model uncertainty</strong> is much harder to quantify.</p>

</article></slide><slide class=""><hgroup><h2>What Can Go Wrong with Predictions?</h2></hgroup><article  id="what-can-go-wrong-with-predictions">

<ul>
<li><p><strong>Bad model</strong>. The statistician does a poor job of modeling the data.</p></li>
<li><p><strong>Quantitative extrapolation</strong>. We try to predict outcomes for cases with predictor values much different from what we see in the data.</p>

<ul>
<li>This is a practical problem in assessing the risk from low exposure to substances that are dangerous in high quantities — consider second-hand tobacco smoke, asbestos, and radon.</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>What Can Go Wrong with Predictions?</h2></hgroup><article  id="what-can-go-wrong-with-predictions-1">

<ul>
<li><p><strong>Qualitative extrapolation</strong>. We try to predict outcomes for observations that come from a different population.</p>

<ul>
<li>We used the body fat model for men to predict the body fat for women.</li>
<li>This is a common problem because circumstances are always changing and it’s hard to judge whether the new case is comparable.</li>
<li>We prefer experimental data to observational data, but sometimes experience from the laboratory does not transfer to real life.</li>
</ul></li>
<li><p><strong>Overconfidence</strong> due to overtraining.</p>

<ul>
<li>Data analysts search for a model that fits their observed data very closely, but the fitted model may not be appropriate for new data.</li>
<li>This can lead to unrealistically small σ ̂.</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>What Can Go Wrong with Predictions?</h2></hgroup><article  id="what-can-go-wrong-with-predictions-2">

<ul>
<li><p><strong>Black swans</strong>. Sometimes errors can appear to be normally distributed because you haven’t seen enough data to be aware of extremes.</p>

<ul>
<li>This is of particular concern in financial applications where stock prices are characterized by mostly small changes (normally distributed) but with infrequent large changes (usually falls).</li>
</ul></li>
</ul></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
